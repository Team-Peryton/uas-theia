{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from theia import utils\n",
    "from dataset.generate import rotate_bound, imageOverlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main sim dataset generation\n",
    "\n",
    "overlay = cv2.imread('target_100.jpg')\n",
    "\n",
    "with open(\"target_positions\", \"w+\") as f:\n",
    "    for img in os.listdir(\"raw_dataset\"):\n",
    "        background = cv2.imread(\"raw_dataset/\"+img)\n",
    "        height, width, channels = background.shape\n",
    "        #overlay1 = noise(overlay)\n",
    "        overlay2 = rotate_bound(overlay, random.randint(0,360))\n",
    "        x = random.randint(200,width-200)\n",
    "        y = random.randint(200,height-200)\n",
    "        new = imageOverlay(background, overlay2, x=x, y=y, width=150)\n",
    "        cv2.imwrite(f\"sim_dataset/{img}\",new)\n",
    "        f.write(f\"{img}, {x}, {y} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "BLUR DETECTION \n",
    "https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "\"\"\"\n",
    "for img in os.listdir(\"sim_dataset\"):\n",
    "    image = cv2.imread(\"sim_dataset/\"+img)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    text = \"Not Blurry\"\n",
    "    # if the focus measure is less than the supplied threshold,\n",
    "    # then the image should be considered \"blurry\"\n",
    "    if fm < 100:\n",
    "        text = \"Blurry\"\n",
    "    # show the image\n",
    "    cv2.putText(image, \"{}: {:.2f}\".format(text, fm), (100, 100),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 3)\n",
    "    utils.display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_160729_071816_0092_RGB.JPG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from theia import utils\n",
    "import os\n",
    "\n",
    "image_number = 50\n",
    "files = [f for f in os.listdir('./dataset/sim_dataset/')]\n",
    "image = cv2.imread('./dataset/sim_dataset/' + files[image_number])\n",
    "print(files[image_number])\n",
    "\n",
    "pts1 = np.array([\n",
    "    [0,0],\n",
    "    [4608, 0],\n",
    "    [0, 3456],\n",
    "    [4608, 3456]\n",
    "])\n",
    "\n",
    "def warp(x_warp, y_warp, image):\n",
    "    pts2 = np.array([\n",
    "        [x_warp,y_warp],\n",
    "        [4608-x_warp, 0],\n",
    "        [0, 3456-y_warp],\n",
    "        [4608, 3456]\n",
    "    ])\n",
    "\n",
    "    h, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "\n",
    "    im1Reg = cv2.warpPerspective(image, h, (4608, 3456))\n",
    "\n",
    "    return im1Reg, h\n",
    "\n",
    "#utils.display(warp(1000,1000, image)[0])\n",
    "\n",
    "h = warp(900,900, image)[1]\n",
    "centre = (2309, 3193)\n",
    "\n",
    "def warp_coord(centre, h):\n",
    "    \"\"\" https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87 \"\"\"\n",
    "    return (\n",
    "        int((h[0][0]*centre[0] + h[0][1]*centre[1] + h[0][2])/(h[2][0]*centre[0] + h[2][1]*centre[1] + h[2][2])),\n",
    "        int((h[1][0]*centre[0] + h[1][1]*centre[1] + h[1][2])/(h[2][0]*centre[0] + h[2][1]*centre[1] + h[2][2]))\n",
    "    )\n",
    "warp_coord(centre, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single threaded version of transformed dataset generation\n",
    "\n",
    "ref = utils.read_positions(\"./dataset/target_positions\")\n",
    "\n",
    "image_number = 50\n",
    "files = [f for f in os.listdir('./dataset/sim_dataset/')]\n",
    "#image = cv2.imread('./dataset/sim_dataset/' + files[image_number])\n",
    "#print(files[image_number])\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    image = cv2.imread('./dataset/sim_dataset/' + file)\n",
    "    print(file)\n",
    "    with open(\"./dataset/target_positions_transformed\", \"w+\") as f:\n",
    "        for i in range(0,1000,100):\n",
    "            for j in range(0,1000,100):\n",
    "                transform, h = warp(i, j, image)\n",
    "                name = f\"{file}_{i}-{j}.jpg\"\n",
    "                cv2.imwrite(f\"./dataset/transform_dataset/{name}\", transform)\n",
    "                centre = ref[file]\n",
    "                x, y = warp_coord(centre, h)\n",
    "                #marked = cv2.circle(transform, (x,y), 10, (0,0,255), thickness=-1)\n",
    "                #utils.display(marked)\n",
    "                f.write(f\"{name}, {x}, {y} \\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from theia import utils\n",
    "from dataset.generate import create_transform_images\n",
    "ref = utils.read_positions(\"./dataset/target_positions\")\n",
    "\n",
    "image_number = 50\n",
    "files = [f for f in os.listdir('./dataset/sim_dataset/')]\n",
    "#image = cv2.imread('./dataset/sim_dataset/' + files[image_number])\n",
    "#print(files[image_number])\n",
    "\n",
    "p = Pool(processes=12)\n",
    "#result = p.map(create_transform_images, files)\n",
    "result = p.map(create_transform_images, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/target_positions_transformed\", \"w+\") as f:\n",
    "    r = [item for sublist in result for item in sublist]\n",
    "    f.writelines(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
