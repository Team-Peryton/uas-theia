{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "from theia import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_bound(image, angle):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "\n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "\n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "\n",
    "    # perform the actual rotation and return the image\n",
    "    rotated_mat = cv2.warpAffine(image, M, (nW, nH))\n",
    "    \n",
    "    tmp = cv2.cvtColor(rotated_mat, cv2.COLOR_RGB2GRAY)\n",
    "    _,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)\n",
    "    b, g, r = cv2.split(rotated_mat)\n",
    "    rgba = [b,g,r,alpha]\n",
    "    dst = cv2.merge(rgba,4)\n",
    "    \n",
    "    return dst\n",
    "\n",
    "\n",
    "def add_gaussian_noise(X_imgs):\n",
    "    gaussian_noise_imgs = []\n",
    "    row, col, _ = X_imgs[0].shape\n",
    "    # Gaussian distribution parameters\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var ** 0.5\n",
    "    \n",
    "    for X_img in X_imgs:\n",
    "        gaussian = np.random.random((row, col, 1)).astype(np.float32)\n",
    "        gaussian = np.concatenate((gaussian, gaussian, gaussian), axis = 2)\n",
    "        gaussian_img = cv2.addWeighted(X_img, 0.75, 0.25 * gaussian, 0.25, 0)\n",
    "        gaussian_noise_imgs.append(gaussian_img)\n",
    "    gaussian_noise_imgs = np.array(gaussian_noise_imgs, dtype = np.float32)\n",
    "    return gaussian_noise_imgs\n",
    "\n",
    "def noise(img):\n",
    "    mean = 0\n",
    "    var = 10\n",
    "    sigma = var ** 0.5\n",
    "    gaussian = np.random.normal(mean, sigma, (100, 100)) #  np.zeros((224, 224), np.float32)\n",
    "    noisy_image = np.zeros(img.shape, np.float32)\n",
    "    \n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        noisy_image = img + gaussian\n",
    "    else:\n",
    "        noisy_image[:, :, 0] = img[:, :, 0] + gaussian\n",
    "        noisy_image[:, :, 1] = img[:, :, 1] + gaussian\n",
    "        noisy_image[:, :, 2] = img[:, :, 2] + gaussian\n",
    "\n",
    "    cv2.normalize(noisy_image, noisy_image, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    noisy_image = noisy_image.astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def increase_brightness(img, value=30):\n",
    "    \"\"\" ??? %$&* \"\"\"\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 255 - (value if value > 0 else 0)\n",
    "    v[v > lim] = 255\n",
    "    #v[v < lim] = 0\n",
    "    #v[v <= lim] += value\n",
    "    v[v >= lim] -= value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def imageOverlay(background, overlay, x, y, width):\n",
    "    \"\"\" overlay an image and set the width of the overlay \"\"\"\n",
    "    \n",
    "    dim = (width, width)\n",
    "    # resize image\n",
    "    overlay = cv2.resize(overlay, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    background_width = background.shape[1]\n",
    "    background_height = background.shape[0]\n",
    "\n",
    "    if x >= background_width or y >= background_height:\n",
    "        return background\n",
    "\n",
    "    h, w = overlay.shape[0], overlay.shape[1]\n",
    "\n",
    "    if x + w > background_width:\n",
    "        w = background_width - x\n",
    "        overlay = overlay[:, :w]\n",
    "\n",
    "    if y + h > background_height:\n",
    "        h = background_height - y\n",
    "        overlay = overlay[:h]\n",
    "\n",
    "    if overlay.shape[2] < 4:\n",
    "        overlay = np.concatenate(\n",
    "            [\n",
    "                overlay,\n",
    "                np.ones((overlay.shape[0], overlay.shape[1], 1), dtype = overlay.dtype) * 255\n",
    "            ],\n",
    "            axis = 2,\n",
    "        )\n",
    "\n",
    "    overlay_image = overlay[..., :3]\n",
    "    mask = overlay[..., 3:] / 255.0\n",
    "\n",
    "    background[y:y+h, x:x+w] = (1.0 - mask) * background[y:y+h, x:x+w] + mask * overlay_image\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = cv2.imread('target_100.jpg')\n",
    "\n",
    "with open(\"target_positions\", \"w+\") as f:\n",
    "    for img in os.listdir(\"raw_dataset\"):\n",
    "        background = cv2.imread(\"raw_dataset/\"+img)\n",
    "        height, width, channels = background.shape\n",
    "        #overlay1 = noise(overlay)\n",
    "        overlay2 = rotate_bound(overlay, random.randint(0,360))\n",
    "        x = random.randint(200,width-200)\n",
    "        y = random.randint(200,height-200)\n",
    "        new = imageOverlay(background, overlay2, x=x, y=y, width=150)\n",
    "        cv2.imwrite(f\"sim_dataset/{img}\",new)\n",
    "        f.write(f\"{img}, {x}, {y} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "BLUR DETECTION \n",
    "https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "\"\"\"\n",
    "for img in os.listdir(\"sim_dataset\"):\n",
    "    image = cv2.imread(\"sim_dataset/\"+img)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    text = \"Not Blurry\"\n",
    "    # if the focus measure is less than the supplied threshold,\n",
    "    # then the image should be considered \"blurry\"\n",
    "    if fm < 100:\n",
    "        text = \"Blurry\"\n",
    "    # show the image\n",
    "    cv2.putText(image, \"{}: {:.2f}\".format(text, fm), (100, 100),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 255), 3)\n",
    "    utils.display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_160729_071816_0092_RGB.JPG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from theia import utils\n",
    "import os\n",
    "\n",
    "image_number = 50\n",
    "files = [f for f in os.listdir('./dataset/sim_dataset/')]\n",
    "image = cv2.imread('./dataset/sim_dataset/' + files[image_number])\n",
    "print(files[image_number])\n",
    "\n",
    "pts1 = np.array([\n",
    "    [0,0],\n",
    "    [4608, 0],\n",
    "    [0, 3456],\n",
    "    [4608, 3456]\n",
    "])\n",
    "\n",
    "def warp(x_warp, y_warp, image):\n",
    "    pts2 = np.array([\n",
    "        [x_warp,y_warp],\n",
    "        [4608-x_warp, 0],\n",
    "        [0, 3456-y_warp],\n",
    "        [4608, 3456]\n",
    "    ])\n",
    "\n",
    "    h, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n",
    "\n",
    "    im1Reg = cv2.warpPerspective(image, h, (4608, 3456))\n",
    "\n",
    "    return im1Reg, h\n",
    "\n",
    "#utils.display(warp(1000,1000, image)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1316, 2532)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = warp(900,900, image)[1]\n",
    "centre = (2309, 3193)\n",
    "\n",
    "def warp_coord(centre, h):\n",
    "    \"\"\" https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#gaf73673a7e8e18ec6963e3774e6a94b87 \"\"\"\n",
    "    return (\n",
    "        int((h[0][0]*centre[0] + h[0][1]*centre[1] + h[0][2])/(h[2][0]*centre[0] + h[2][1]*centre[1] + h[2][2])),\n",
    "        int((h[1][0]*centre[0] + h[1][1]*centre[1] + h[1][2])/(h[2][0]*centre[0] + h[2][1]*centre[1] + h[2][2]))\n",
    "    )\n",
    "warp_coord(centre, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "ref = utils.read_positions(\"./dataset/target_positions\")\n",
    "\n",
    "image_number = 50\n",
    "files = [f for f in os.listdir('./dataset/sim_dataset/')]\n",
    "#image = cv2.imread('./dataset/sim_dataset/' + files[image_number])\n",
    "#print(files[image_number])\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    image = cv2.imread('./dataset/sim_dataset/' + file)\n",
    "    print(file)\n",
    "    with open(\"./dataset/target_positions_transformed\", \"w+\") as f:\n",
    "        for i in range(0,1000,100):\n",
    "            for j in range(0,1000,100):\n",
    "                transform, h = warp(i, j, image)\n",
    "                name = f\"{file}_{i}-{j}.jpg\"\n",
    "                cv2.imwrite(f\"./dataset/transform_dataset/{name}\", transform)\n",
    "                centre = ref[file]\n",
    "                x, y = warp_coord(centre, h)\n",
    "                #marked = cv2.circle(transform, (x,y), 10, (0,0,255), thickness=-1)\n",
    "                #utils.display(marked)\n",
    "                f.write(f\"{name}, {x}, {y} \\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from theia import utils\n",
    "from dataset.generate import create_transform_images\n",
    "ref = utils.read_positions(\"./dataset/target_positions\")\n",
    "\n",
    "image_number = 50\n",
    "files = [f for f in os.listdir('./dataset/sim_dataset/')]\n",
    "#image = cv2.imread('./dataset/sim_dataset/' + files[image_number])\n",
    "#print(files[image_number])\n",
    "\n",
    "p = Pool(processes=12)\n",
    "#result = p.map(create_transform_images, files)\n",
    "result = p.map(create_transform_images, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/target_positions_transformed\", \"w+\") as f:\n",
    "    r = [item for sublist in result for item in sublist]\n",
    "    f.writelines(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
